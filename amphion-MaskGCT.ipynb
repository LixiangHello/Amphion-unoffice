{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd48629",
   "metadata": {},
   "source": [
    "## MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-Paper-COLOR.svg)](https://arxiv.org/abs/2409.00750) [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-model-yellow)](https://huggingface.co/amphion/maskgct) [![hf](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-demo-pink)](https://huggingface.co/spaces/amphion/maskgct) [![readme](https://img.shields.io/badge/README-Key%20Features-blue)](https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct)\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "**Clone and install**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9c46d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/open-mmlab/Amphion.git\n",
    "!cd Amphion/\n",
    "# bash ./models/tts/maskgct/env.sh\n",
    "!pip install -r requirements.txt -U\n",
    "!sudo apt-get update && sudo apt-get install espeak-ng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56f72c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Model download**\n",
    "\n",
    "We provide the following pretrained checkpoints:\n",
    "\n",
    "\n",
    "| Model Name          | Description   |    \n",
    "|-------------------|-------------|\n",
    "| [Semantic Codec](https://huggingface.co/amphion/MaskGCT/tree/main/semantic_codec)      | Converting speech to semantic tokens. |\n",
    "| [Acoustic Codec](https://huggingface.co/amphion/MaskGCT/tree/main/acoustic_codec)      | Converting speech to acoustic tokens and reconstructing waveform from acoustic tokens. |\n",
    "| [MaskGCT-T2S](https://huggingface.co/amphion/MaskGCT/tree/main/t2s_model)         | Predicting semantic tokens with text and prompt semantic tokens.             |\n",
    "| [MaskGCT-S2A](https://huggingface.co/amphion/MaskGCT/tree/main/s2a_model)         | Predicts acoustic tokens conditioned on semantic tokens.              |\n",
    "\n",
    "You can download all pretrained checkpoints from [HuggingFace](https://huggingface.co/amphion/MaskGCT/tree/main) or use huggingface api.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d30815",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "\n",
    "# # download semantic codec ckpt\n",
    "# semantic_code_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"semantic_codec/model.safetensors\")\n",
    "\n",
    "# # download acoustic codec ckpt\n",
    "# codec_encoder_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"acoustic_codec/model.safetensors\")\n",
    "# codec_decoder_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"acoustic_codec/model_1.safetensors\")\n",
    "\n",
    "# # download t2s model ckpt\n",
    "# t2s_model_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"t2s_model/model.safetensors\")\n",
    "\n",
    "# # download s2a model ckpt\n",
    "# s2a_1layer_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_1layer/model.safetensors\")\n",
    "# s2a_full_ckpt = hf_hub_download(\"amphion/MaskGCT\", filename=\"s2a_model/s2a_model_full/model.safetensors\")\n",
    "\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    'amphion/MaskGCT', allow_patterns=[\n",
    "        'semantic_codec/model.safetensors',\n",
    "        'acoustic_codec/model.safetensors',\n",
    "        'acoustic_codec/model_1.safetensors',\n",
    "        't2s_model/model.safetensors',\n",
    "        's2a_model/s2a_model_1layer/model.safetensors',\n",
    "        's2a_model/s2a_model_full/model.safetensors'\n",
    "    ], local_dir='./ckpts'\n",
    ")\n",
    "\n",
    "snapshot_download(\n",
    "    'AI-ModelScope/w2v-bert-2.0', local_dir='./ckpts/w2v-bert-2.0'\n",
    ")\n",
    "\n",
    "# 修改 models/tts/maskgct/maskgct_utils.py\n",
    "# \"facebook/w2v-bert-2.0\"  -> \"./ckpts/w2v-bert-2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3047f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Basic Usage**\n",
    "\n",
    "You can use the following code to generate speech from text and a prompt speech.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4080453-a642-4a49-a454-aff0c352025b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.tts.maskgct.maskgct_utils import *\n",
    "from huggingface_hub import hf_hub_download\n",
    "import safetensors\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "# build model\n",
    "device = torch.device(\"cuda:0\")\n",
    "cfg_path = \"./models/tts/maskgct/config/maskgct.json\"\n",
    "cfg = load_config(cfg_path)\n",
    "# 1. build semantic model (w2v-bert-2.0)\n",
    "semantic_model, semantic_mean, semantic_std = build_semantic_model(device)\n",
    "# 2. build semantic codec\n",
    "semantic_codec = build_semantic_codec(cfg.model.semantic_codec, device)\n",
    "# 3. build acoustic codec\n",
    "codec_encoder, codec_decoder = build_acoustic_codec(cfg.model.acoustic_codec, device)\n",
    "# 4. build t2s model\n",
    "t2s_model = build_t2s_model(cfg.model.t2s_model, device)\n",
    "# 5. build s2a model\n",
    "s2a_model_1layer = build_s2a_model(cfg.model.s2a_model.s2a_1layer, device)\n",
    "s2a_model_full =  build_s2a_model(cfg.model.s2a_model.s2a_full, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2eced-04ff-48b9-ba00-3c0dc9556bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "semantic_code_ckpt = './ckpts/semantic_codec/model.safetensors'\n",
    "codec_encoder_ckpt = './ckpts/acoustic_codec/model.safetensors'\n",
    "codec_decoder_ckpt = './ckpts/acoustic_codec/model_1.safetensors'\n",
    "t2s_model_ckpt = './ckpts/t2s_model/model.safetensors'\n",
    "s2a_1layer_ckpt = './ckpts/s2a_model/s2a_model_1layer/model.safetensors'\n",
    "s2a_full_ckpt = './ckpts/s2a_model/s2a_model_full/model.safetensors'\n",
    "\n",
    "\n",
    "# load semantic codec\n",
    "safetensors.torch.load_model(semantic_codec, semantic_code_ckpt)\n",
    "# load acoustic codec\n",
    "safetensors.torch.load_model(codec_encoder, codec_encoder_ckpt)\n",
    "safetensors.torch.load_model(codec_decoder, codec_decoder_ckpt)\n",
    "# load t2s model\n",
    "safetensors.torch.load_model(t2s_model, t2s_model_ckpt)\n",
    "# load s2a model\n",
    "safetensors.torch.load_model(s2a_model_1layer, s2a_1layer_ckpt)\n",
    "safetensors.torch.load_model(s2a_model_full, s2a_full_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245a24b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inference\n",
    "save_path = \"test.mp3\"\n",
    "prompt_wav_path = \"./models/tts/maskgct/wav/prompt.wav\"\n",
    "prompt_text = \" We do not break. We never give in. We never back down.\"\n",
    "target_text = \"In this paper, we introduce MaskGCT, a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision.\"\n",
    "target_text = '这种模式本质就是吃大锅饭，地方对于干工作是没什么积极性的，干好了给国家，干不好中央给兜底，那还努力啥？'\n",
    "# target_text = \"你好，我是小Kitty!\"\n",
    "# Specify the target duration (in seconds). If target_len = None, we use a simple rule to predict the target duration.\n",
    "target_len = None\n",
    "\n",
    "maskgct_inference_pipeline = MaskGCT_Inference_Pipeline(\n",
    "    semantic_model,\n",
    "    semantic_codec,\n",
    "    codec_encoder,\n",
    "    codec_decoder,\n",
    "    t2s_model,\n",
    "    s2a_model_1layer,\n",
    "    s2a_model_full,\n",
    "    semantic_mean,\n",
    "    semantic_std,\n",
    "    device,\n",
    ")\n",
    "\n",
    "recovered_audio = maskgct_inference_pipeline.maskgct_inference(\n",
    "    prompt_wav_path, prompt_text, target_text, \"en\", \"zh\", target_len=target_len\n",
    ")\n",
    "sf.write(save_path, recovered_audio, 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc7b6a-bbcd-4531-82dd-d795e232e02a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "display(Audio(save_path, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb230cd3-91f5-41db-9b46-91ce0da557ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdbcf7-0416-4fb6-b44e-fde4c2de7815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "display(Audio('./models/tts/maskgct/wav/prompt.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c735908-05a8-48b5-b007-dbf689435d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48299885-f675-4493-b9f0-c03fbdc7fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
